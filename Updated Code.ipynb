{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b6332f-68d4-4d83-9678-80162bd8a863",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d067bf5d-bf65-49ae-9e48-9b94c25870fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f43656f-156c-4658-872d-3e15be7dbd4e",
   "metadata": {},
   "source": [
    "# Initialize MediaPipe Pose and Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e634391-095a-4063-aafb-10a432cc95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1801f49a-9529-48cb-b22f-0621d568885c",
   "metadata": {},
   "source": [
    "# Function to Calculate Angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35d9264-e6e9-4452-9ff4-46d2377b3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculates the angle between three points.\"\"\"\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.degrees(radians)\n",
    "    angle = np.abs(angle)\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad10d8c-bc92-428b-98ec-3f8706c09d05",
   "metadata": {},
   "source": [
    "# NEW Helper Function to get left knee angle if landmarks are visible \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea0ce89-4c00-479b-99d7-02f769cdb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_left_knee_angle_if_visible(landmarks, visibility_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculates the left knee angle if hip, knee, and ankle landmarks are sufficiently visible.\n",
    "    Returns the angle in degrees, or None if landmarks are not clearly visible.\n",
    "    \"\"\"\n",
    "    # Access landmark objects\n",
    "    lm_left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "    lm_left_knee = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value]\n",
    "    lm_left_ankle = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value]\n",
    "\n",
    "    # Check visibility\n",
    "    if not (lm_left_hip.visibility > visibility_threshold and\n",
    "            lm_left_knee.visibility > visibility_threshold and\n",
    "            lm_left_ankle.visibility > visibility_threshold):\n",
    "        return None  # Not enough reliable data\n",
    "\n",
    "    # Get coordinates\n",
    "    left_hip_coord = [lm_left_hip.x, lm_left_hip.y]\n",
    "    left_knee_coord = [lm_left_knee.x, lm_left_knee.y]\n",
    "    left_ankle_coord = [lm_left_ankle.x, lm_left_ankle.y]\n",
    "    \n",
    "    return calculate_angle(left_hip_coord, left_knee_coord, left_ankle_coord)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6311eff-5022-40b0-b842-fdac0a91c707",
   "metadata": {},
   "source": [
    "#  Functions to Check Squat Position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212c748b-335d-4c5b-a7a3-98fe4eff197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_squat_down(landmarks):\n",
    "    \"\"\"Checks if the person is in the 'down' position of a squat FOR COUNTING.\"\"\"\n",
    "    angle = get_left_knee_angle_if_visible(landmarks)\n",
    "    if angle is None:\n",
    "        return False\n",
    "    return angle < 100  # Original threshold for counter\n",
    "\n",
    "def is_squat_up(landmarks):\n",
    "    \"\"\"Checks if the person is in the 'up' position of a squat.\"\"\"\n",
    "    angle = get_left_knee_angle_if_visible(landmarks)\n",
    "    if angle is None:\n",
    "        return False\n",
    "    return angle > 160\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b50ea3-c0c5-4201-a3b1-611304bf5eb0",
   "metadata": {},
   "source": [
    "# Helper Function for \"Good Depth\" FEEDBACK \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c5e867-c368-43f9-b811-798b4136958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_good_depth_for_feedback_message(landmarks, threshold):\n",
    "    \"\"\"Checks if squat depth is sufficient for 'Good Depth' feedback message.\"\"\"\n",
    "    angle = get_left_knee_angle_if_visible(landmarks)\n",
    "    if angle is None:\n",
    "        return False\n",
    "    return angle < threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17078f5-0f43-43c5-8f0f-1300a92b19a9",
   "metadata": {},
   "source": [
    "# Function for getting feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "696b82f4-d126-4bda-be8e-65e374eae2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedback(landmarks):\n",
    "    \"\"\"Provides feedback on squat form.\"\"\"\n",
    "    # Check visibility of necessary landmarks for lean feedback\n",
    "    if not (landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].visibility > 0.5 and\n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].visibility > 0.5 and\n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].visibility > 0.5):\n",
    "        return \"Tracker Obscured\"\n",
    "\n",
    "    left_hip_coord = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "    left_shoulder_coord = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "    left_knee_coord = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "\n",
    "    LEANING_THRESHOLD = 90\n",
    "    angle_hsk = calculate_angle(left_hip_coord, left_shoulder_coord, left_knee_coord)\n",
    "    is_leaning_too_much = angle_hsk < LEANING_THRESHOLD\n",
    "\n",
    "    is_generally_down_for_counter = is_squat_down(landmarks)\n",
    "    is_generally_up = is_squat_up(landmarks)\n",
    "    in_transition = not is_generally_down_for_counter and not is_generally_up\n",
    "\n",
    "    GOOD_DEPTH_FEEDBACK_ANGLE_THRESHOLD = 80\n",
    "    achieved_feedback_good_depth = is_good_depth_for_feedback_message(landmarks, GOOD_DEPTH_FEEDBACK_ANGLE_THRESHOLD)\n",
    "\n",
    "    if achieved_feedback_good_depth:\n",
    "        if is_leaning_too_much:\n",
    "            return \"Good Depth, Keep Chest Up\"\n",
    "        else:\n",
    "            return \"Good Depth\"\n",
    "    elif is_generally_down_for_counter:\n",
    "        if is_leaning_too_much:\n",
    "            return \"Go Deeper & Keep Chest Up\"\n",
    "        else:\n",
    "            return \"Go Deeper\"\n",
    "    elif is_generally_up:\n",
    "        if is_leaning_too_much:\n",
    "            return \"Stand Straight\"\n",
    "        else:\n",
    "            return \"Up\"\n",
    "    elif in_transition:\n",
    "        if is_leaning_too_much:\n",
    "            return \"Keep Chest Up while moving\"\n",
    "        else:\n",
    "            return \"Keep Going Down\"\n",
    "    else:\n",
    "        if is_leaning_too_much:\n",
    "            return \"Check Posture\"\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b336826-2f1b-45e0-a931-178dbb52152e",
   "metadata": {},
   "source": [
    "# Process Squat Video function with Tracker Accuracy Feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b848a775-f6fa-43b1-9ad6-d7484b515aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_squat_video(input_video, output_video, show_realtime=True):\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file: {input_video}\")\n",
    "        return\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    if fps == 0:\n",
    "        fps = 20\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    squat_counter = 0\n",
    "    squat_state = \"up\"\n",
    "    min_frame_interval = 15\n",
    "    frame_count = 0\n",
    "    last_counted_frame = -min_frame_interval\n",
    "\n",
    "    # Renamed for clarity: these are the ENUMs, not the indices yet\n",
    "    LANDMARKS_TO_DRAW_ENUM = [\n",
    "        mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER,\n",
    "        mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.RIGHT_HIP,\n",
    "        mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.RIGHT_KNEE,\n",
    "        mp_pose.PoseLandmark.LEFT_ANKLE, mp_pose.PoseLandmark.RIGHT_ANKLE\n",
    "    ]\n",
    "    # Integer indices of landmarks for drawing and accuracy calculation\n",
    "    KEY_LANDMARK_INDICES = [lm.value for lm in LANDMARKS_TO_DRAW_ENUM]\n",
    "    VISIBILITY_THRESHOLD_FOR_ACCURACY = 0.75\n",
    "\n",
    "    CUSTOM_SQUAT_CONNECTIONS = [\n",
    "        (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER),\n",
    "        (mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.RIGHT_HIP),\n",
    "        (mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_HIP),\n",
    "        (mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_HIP),\n",
    "        (mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE),\n",
    "        (mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE),\n",
    "        (mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE),\n",
    "        (mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_ANKLE)\n",
    "    ]\n",
    "    landmark_point_spec = mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=-1, circle_radius=4)\n",
    "    connection_line_spec = mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "\n",
    "    GREEN_COLOR = (0, 255, 0)\n",
    "    RED_COLOR = (0, 0, 255)\n",
    "    WHITE_COLOR = (255, 255, 255)\n",
    "    YELLOW_COLOR = (0, 255, 255)\n",
    "\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # Use a different variable name\n",
    "            image_rgb.flags.writeable = False\n",
    "            results = pose.process(image_rgb)\n",
    "            # image_rgb.flags.writeable = True # Not strictly needed if not modifying image_rgb further for mediapipe\n",
    "            # Frame is kept as BGR for cv2 drawing\n",
    "\n",
    "            tracker_accuracy_feedback = \"Tracker Accuracy: N/A\"\n",
    "\n",
    "            if results.pose_landmarks:\n",
    "                all_landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "                # --- Tracker Accuracy Calculation ---\n",
    "                visible_key_landmarks_count = 0\n",
    "                for lm_idx in KEY_LANDMARK_INDICES: # Use the consolidated list of indices\n",
    "                    if all_landmarks[lm_idx].visibility > VISIBILITY_THRESHOLD_FOR_ACCURACY:\n",
    "                        visible_key_landmarks_count += 1\n",
    "                \n",
    "                if KEY_LANDMARK_INDICES:\n",
    "                    accuracy_percentage = (visible_key_landmarks_count / len(KEY_LANDMARK_INDICES)) * 100\n",
    "                    accuracy_status = \"Poor\"\n",
    "                    if accuracy_percentage >= 85:\n",
    "                        accuracy_status = \"Good\"\n",
    "                    elif accuracy_percentage >= 60:\n",
    "                        accuracy_status = \"Fair\"\n",
    "                    tracker_accuracy_feedback = f\"Tracker Accuracy: {accuracy_percentage:.0f}% - {accuracy_status}\"\n",
    "                else:\n",
    "                    tracker_accuracy_feedback = \"Tracker Accuracy: (No key LMs defined)\"\n",
    "\n",
    "                # Landmark drawing (UNCHANGED)\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=frame,\n",
    "                    landmark_list=results.pose_landmarks,\n",
    "                    connections=CUSTOM_SQUAT_CONNECTIONS,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=connection_line_spec\n",
    "                )\n",
    "                for idx, landmark_data in enumerate(all_landmarks):\n",
    "                    if idx in KEY_LANDMARK_INDICES: # Use the consolidated list of indices\n",
    "                        if landmark_data.visibility > 0.5:\n",
    "                            cx, cy = int(landmark_data.x * frame_width), int(landmark_data.y * frame_height)\n",
    "                            cv2.circle(frame, (cx, cy), landmark_point_spec.circle_radius, landmark_point_spec.color, landmark_point_spec.thickness)\n",
    "                \n",
    "                form_feedback = get_feedback(all_landmarks)\n",
    "\n",
    "                # Counter logic (UNCHANGED)\n",
    "                if is_squat_down(all_landmarks) and squat_state == \"up\" and frame_count - last_counted_frame > min_frame_interval:\n",
    "                    squat_counter += 1\n",
    "                    squat_state = \"down\"\n",
    "                    last_counted_frame = frame_count\n",
    "                elif is_squat_up(all_landmarks) and squat_state == \"down\":\n",
    "                    squat_state = \"up\"\n",
    "\n",
    "                # --- Text Drawing ---\n",
    "                cv2.putText(frame, f\"Count: {squat_counter}\", (20, 40),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, WHITE_COLOR, 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Simplified Feedback Text Color Logic\n",
    "                if not form_feedback:\n",
    "                    form_feedback_color = WHITE_COLOR \n",
    "                elif \"Good Depth\" in form_feedback or form_feedback == \"Up\":\n",
    "                    form_feedback_color = GREEN_COLOR\n",
    "                else: # All other non-empty feedbacks are corrective\n",
    "                    form_feedback_color = RED_COLOR\n",
    "\n",
    "                if form_feedback:\n",
    "                    cv2.putText(frame, form_feedback, (20, 80),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, form_feedback_color, 2, cv2.LINE_AA)\n",
    "                \n",
    "                cv2.putText(frame, tracker_accuracy_feedback, (20, 120),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(frame, \"No person detected\", (20, 80), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, RED_COLOR, 2, cv2.LINE_AA)\n",
    "                cv2.putText(frame, tracker_accuracy_feedback, (20, 120), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2, cv2.LINE_AA)\n",
    "\n",
    "            out.write(frame)\n",
    "\n",
    "            if show_realtime:\n",
    "                cv2.imshow('Squat Analysis - Realtime', frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    if show_realtime:\n",
    "        cv2.destroyAllWindows()\n",
    "    print(f\"Video with feedback saved as: {output_video}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19984b5-1f6c-4023-8ea7-ea38ad4183af",
   "metadata": {},
   "source": [
    "# File Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9843c8-b2fc-4881-8815-c703da2242f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path = \"squats.mp4\" \n",
    "output_video_path = \"squats_output.mp4\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890016c7-2bac-4603-8363-a0e743136d4e",
   "metadata": {},
   "source": [
    "# Calling the video processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9df85044-f194-4ace-8f07-2d90d319e87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video with feedback saved as: squats_output.mp4\n"
     ]
    }
   ],
   "source": [
    "process_squat_video(input_video_path, output_video_path, show_realtime=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db1fac-2232-4475-b27d-83cbbb852f37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
